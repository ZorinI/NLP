{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc82b72d",
   "metadata": {
    "id": "8e49aca8"
   },
   "source": [
    "# Домашнее задание №9. Языковое моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b8f3ad",
   "metadata": {
    "id": "730d8ff7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207fdf2",
   "metadata": {
    "id": "e2bc2074"
   },
   "source": [
    "## Заданиe\n",
    "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe13f1",
   "metadata": {
    "id": "1e53df14"
   },
   "source": [
    "## План решения\n",
    "\n",
    "[0. Загрузка и просмотр данных](#section_0)\n",
    "\n",
    "[1. Модель генерации текста](#section_1)\n",
    "\n",
    "[1.1. Подготовка данных](#section_1.1)\n",
    "\n",
    "[1.2. Построение модели](#section_1.2)\n",
    "\n",
    "[1.3. Обучение модели](#section_1.3)\n",
    "\n",
    "[2. Генерация текста](#section_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e6ed4",
   "metadata": {
    "id": "26465080"
   },
   "source": [
    "## 0. Загрузка и просмотр данных  <a id='section_0'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734f9494",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29c47f44",
    "outputId": "9b1533d4-f3bc-4514-ab22-4af99d53a3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 286984 characters\n"
     ]
    }
   ],
   "source": [
    "#загружаем файл\n",
    "text = open('evgenyi_onegin.txt', 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# Определяем длину текста (количество букв в нем)\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15439114",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0ab3fa1",
    "outputId": "9e2044e8-4cd3-406c-a995-c6f93ef2e7a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Александр Сергеевич Пушкин\n",
      "\n",
      "                                Евгений Онегин\n",
      "                                Роман в стихах\n",
      "\n",
      "                        Не мысля гордый свет забавить,\n",
      "                        Вниманье дружбы возлюбя,\n",
      "                        Хотел бы я тебе представить\n",
      "                        Залог достойнее тебя,\n",
      "                        Достойнее души прекрасной,\n",
      "                        Святой исполненной мечты,\n",
      "                        Поэзии живой и ясной,\n",
      "                        Высо\n"
     ]
    }
   ],
   "source": [
    "#просматриваем фрагмент текста\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15bd21c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf64bb62",
    "outputId": "0f8507bf-e7ba-4fa4-9c99-52d0220c039c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 unique characters\n"
     ]
    }
   ],
   "source": [
    "# уникальные буквы в файле\n",
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0afff00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "932e59e0",
    "outputId": "2a332d1e-6c99-4c14-b56c-c0261eb45494"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '}',\n",
       " 'А',\n",
       " 'Б',\n",
       " 'В',\n",
       " 'Г',\n",
       " 'Д',\n",
       " 'Е',\n",
       " 'Ж',\n",
       " 'З',\n",
       " 'И',\n",
       " 'К',\n",
       " 'Л',\n",
       " 'М',\n",
       " 'Н',\n",
       " 'О',\n",
       " 'П',\n",
       " 'Р',\n",
       " 'С',\n",
       " 'Т',\n",
       " 'У',\n",
       " 'Ф',\n",
       " 'Х',\n",
       " 'Ц',\n",
       " 'Ч',\n",
       " 'Ш',\n",
       " 'Ь',\n",
       " 'Э',\n",
       " 'Ю',\n",
       " 'Я',\n",
       " 'а',\n",
       " 'б',\n",
       " 'в',\n",
       " 'г',\n",
       " 'д',\n",
       " 'е',\n",
       " 'ж',\n",
       " 'з',\n",
       " 'и',\n",
       " 'й',\n",
       " 'к',\n",
       " 'л',\n",
       " 'м',\n",
       " 'н',\n",
       " 'о',\n",
       " 'п',\n",
       " 'р',\n",
       " 'с',\n",
       " 'т',\n",
       " 'у',\n",
       " 'ф',\n",
       " 'х',\n",
       " 'ц',\n",
       " 'ч',\n",
       " 'ш',\n",
       " 'щ',\n",
       " 'ъ',\n",
       " 'ы',\n",
       " 'ь',\n",
       " 'э',\n",
       " 'ю',\n",
       " 'я']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#словарь из букв\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e8075d",
   "metadata": {
    "id": "69883812"
   },
   "outputs": [],
   "source": [
    "# Задаем отображения из множества уникальных букв в множество индексов\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}  #{уникальная буквы : ее индекс из словаря}\n",
    "\n",
    "# Представление текста в виде последовательности чисел (индексы букв из словаря)\n",
    "idx2char = np.array(vocab) # список из символов словаря (можно по индексу извлекать букву)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1969b035",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec0dc39e",
    "outputId": "d7d88869-840c-41f0-e201-11f99d42d67c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Александр Сергеевич Пушкин\n",
      "\n",
      "                                Евгений Онегин\n",
      "                                Роман в стихах\n",
      "\n",
      "                        Не мысля гордый свет забавить,\n",
      "                        Вниманье дружбы возлюбя,\n",
      "                        Хотел бы я тебе представить\n",
      "                        Залог достойнее тебя,\n",
      "                        Достойнее души прекрасной,\n",
      "                        Святой исполненной мечты,\n",
      "                        Поэзии живой и ясной,\n",
      "                        Высо\n",
      "[ 71 110 104 109 116  99 112 103 115   1  87 104 115 102 104 104 101 107\n",
      " 122   1  85 118 123 109 107 112   0   0   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1  76 101 102 104 112 107 108   1  84 112 104 102\n",
      " 107 112   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  86\n",
      " 113 111  99 112   1 101   1 116 117 107 120  99 120   0   0   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1  83 104   1 111 126 116 110 130   1 102 113 115 103 126 108\n",
      "   1 116 101 104 117   1 106  99 100  99 101 107 117 127   7   0   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1  73 112 107 111  99 112 127 104   1 103 115 118 105 100\n",
      " 126   1 101 113 106 110 129 100 130   7   0   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  91\n",
      " 113 117 104 110   1 100 126   1 130   1 117 104 100 104   1 114 115 104\n",
      " 103 116 117  99 101 107 117 127   0   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  78  99 110\n",
      " 113 102   1 103 113 116 117 113 108 112 104 104   1 117 104 100 130   7\n",
      "   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1  75 113 116 117 113 108 112 104 104   1 103\n",
      " 118 123 107   1 114 115 104 109 115  99 116 112 113 108   7   0   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1  87 101 130 117 113 108   1 107 116 114 113 110 112 104\n",
      " 112 112 113 108   1 111 104 122 117 126   7   0   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "  85 113 128 106 107 107   1 105 107 101 113 108   1 107   1 130 116 112\n",
      " 113 108   7   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1  73 126 116 113]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text[:500]), print(text_as_int[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc306d2",
   "metadata": {
    "id": "8b9bac30"
   },
   "source": [
    "## 1. Модель генерации текста  <a id='section_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb8b7d",
   "metadata": {
    "id": "3e21c9dd"
   },
   "source": [
    "### 1.1. Подготовка данных <a id='section_1.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f58d07c7",
   "metadata": {
    "id": "ab92f43b"
   },
   "outputs": [],
   "source": [
    "# Максимальная длина предложения для входных данных (в буквах)\n",
    "seq_length = 100\n",
    "\n",
    "#количество эпох\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40adbcd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d719cfba",
    "outputId": "f8410171-bbf8-4252-e9e9-82c608b3a3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286984\n",
      "tf.Tensor(71, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# создаем датасет из данных\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "for element in char_dataset:\n",
    "    print(len(char_dataset))\n",
    "    print(element)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01df9304",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20868ac6",
    "outputId": "476ad927-ed1e-4501-883d-1eea89f8a5df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А\n"
     ]
    }
   ],
   "source": [
    "for element in char_dataset:\n",
    "    print(idx2char[element.numpy()])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eaa5c78e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90cc12d5",
    "outputId": "2913ae33-4db0-4b4e-d7d8-3477d34f4978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n",
      "'      Роман в стихах\\n\\n                        Не мысля гордый свет забавить,\\n                        '\n",
      "'Вниманье дружбы возлюбя,\\n                        Хотел бы я тебе представить\\n                        '\n",
      "'Залог достойнее тебя,\\n                        Достойнее души прекрасной,\\n                        Свят'\n",
      "'ой исполненной мечты,\\n                        Поэзии живой и ясной,\\n                        Высоких д'\n"
     ]
    }
   ],
   "source": [
    "#создаем батчи из seq_length+1 элементов\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True) #drop_remainder удаляет неполный батч (с длиной менее seq_length+1)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f53f4ea6",
   "metadata": {
    "id": "efa73bdf"
   },
   "outputs": [],
   "source": [
    "# Разбиваем каждый батч на признаки и целевую переменную (последнюю букву)\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "#применяем функцию split_input_target ко всем батчам\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48ab7134",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74ff7139",
    "outputId": "dbb9fbb5-8a5b-41d5-f1d4-183fa3292049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество батчей: 2841\n",
      "Данные: [ 71 110 104 109 116  99 112 103 115   1  87 104 115 102 104 104 101 107\n",
      " 122   1  85 118 123 109 107 112   0   0   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1  76 101 102 104 112 107 108   1  84 112 104 102\n",
      " 107 112   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1]\n",
      "Целевая переменная: [110 104 109 116  99 112 103 115   1  87 104 115 102 104 104 101 107 122\n",
      "   1  85 118 123 109 107 112   0   0   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1  76 101 102 104 112 107 108   1  84 112 104 102 107\n",
      " 112   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset:\n",
    "    print(f'Количество батчей: {len(dataset)}')\n",
    "    print(f'Данные: {input_example}')\n",
    "    print(f'Целевая переменная: {target_example}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6bc3294",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dbcf0cf",
    "outputId": "27ee37c5-4a2e-4983-a21f-2d698223bf55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                         '\n",
      "Target data: 'лександр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f8f2d9",
   "metadata": {
    "id": "ca631299"
   },
   "source": [
    "### 1.2. Построение модели <a id='section_1.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c152f97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83b28376",
    "outputId": "38e2e986-8f76-4a51-fdeb-0fd2946333e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# размер батча\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# размер буфера для перемешивания данных\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# перемешивание разделенных данных\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d140549",
   "metadata": {
    "id": "478828f5"
   },
   "outputs": [],
   "source": [
    "# Длина словаря в буквах\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Размерность эмбеддинга\n",
    "embedding_dim = 256\n",
    "\n",
    "# Число ячеек\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daacfb40",
   "metadata": {
    "id": "08531279"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "                                 \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e61e8dd8",
   "metadata": {
    "id": "3ab3f4fb"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8aa99533",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7da778c0",
    "outputId": "148f03db-401d-4729-d646-685b82156e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 131) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9880ecd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e7df002",
    "outputId": "cea8f143-2962-4899-8024-c3b49393bfe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           33536     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 131)           134275    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,592,899\n",
      "Trainable params: 30,592,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b388a4dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e1a6a1e",
    "outputId": "818b0043-27c9-4be1-ab26-d99f5ef6fd5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 131), dtype=float32, numpy=\n",
       "array([[-3.81107156e-06, -2.06065379e-05,  6.71569887e-06, ...,\n",
       "         1.42809695e-05,  5.45804687e-06, -1.44679689e-07],\n",
       "       [-9.50220056e-06, -4.80803355e-05,  2.69599659e-05, ...,\n",
       "         2.99920703e-05,  1.01583400e-05,  8.11330665e-06],\n",
       "       [-1.52972734e-05, -5.57256208e-05,  8.76246777e-05, ...,\n",
       "         4.71799140e-05,  2.90016451e-05,  4.86779172e-05],\n",
       "       ...,\n",
       "       [-2.63679004e-03,  1.84492106e-04,  3.41221457e-03, ...,\n",
       "        -2.57675396e-03, -1.28943566e-03,  1.89420162e-03],\n",
       "       [-2.65124207e-03,  2.40691399e-04,  3.25254072e-03, ...,\n",
       "        -2.80535407e-03, -1.57234259e-03,  1.79659470e-03],\n",
       "       [-2.68921396e-03,  3.05590627e-04,  3.12503008e-03, ...,\n",
       "        -3.01102805e-03, -1.84767391e-03,  1.70347968e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbad4e7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1878dd06",
    "outputId": "d95fec34-662f-4639-c9e0-ea224ff7edbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([118,  11,  14,  29,  94,  82,  44,  81,  76,  95,  88,  18,  69,\n",
       "       107,  80,  32,   7, 107,  72, 107,  21,  88,  12,  29,  40, 109,\n",
       "        27,  15,  54,  61,  24,  62, 123, 122,  90,  15, 112,  39,   5,\n",
       "       115,   4, 120,  61,  18,  47,  84,  56, 111,   6, 123,  21,  72,\n",
       "       100, 112,  92,  75,  91,  77,  50, 101,  40,   2, 108,  52,  27,\n",
       "       102,  29,  57,  74,  60,  29,  33, 104,  39,  32,  59, 113,   6,\n",
       "       109,  17,  64,  21, 103, 127,  14,  93,   8,  85,  40,  34,  33,\n",
       "       104,  72,  64, 108, 106, 118,  42, 111,  38])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#индексы букв (извлекаем выборки из категориального распределения)\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1) #количество независимых выборок 1\n",
    "\n",
    "#убираем лишнюю размерность (список индексов)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56edf938",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97b47a2a",
    "outputId": "2750da91-98cf-45ab-911e-7b56fb382d00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " ' Позвольте мне, читатель мой,\\n                        Заняться старшею сестрой.\\n\\n                   '\n",
      "\n",
      "Next Char Predictions: \n",
      " \"у14GШМYЛЕЬТ8{иКL,иБи;Т2GTкE5krBsшчФ5нS(р'хr8cОmм)ш;БбнЦДХЖfвT!йhEгGnГqGMеSLpо)к7u;дь4Ч-ПTNMеБuйзуWмR\"\n"
     ]
    }
   ],
   "source": [
    "#входной пример\n",
    "#возвращаем строку\n",
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "\n",
    "#предсказанная буква\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0dc3e",
   "metadata": {
    "id": "b1147f07"
   },
   "source": [
    "### 1.3. Обучение модели <a id='section_1.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19fd3c60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d0481a1",
    "outputId": "a6ce344f-eef9-43ac-da35-d54079b59d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 131)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.8751607\n"
     ]
    }
   ],
   "source": [
    "#функция потерь\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccfc5322",
   "metadata": {
    "id": "6a3a1e61"
   },
   "outputs": [],
   "source": [
    "#компиляция модели\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aafcb4af",
   "metadata": {
    "id": "98161238"
   },
   "outputs": [],
   "source": [
    "# место для хранения checkpoint\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Имя файла checkpoint\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_freq=44*100, # сохраняем каждую сотую эпоху - в эпохе 44 батча (это видно при запуске обучения)\n",
    "    save_weights_only=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e2742c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51e63822",
    "outputId": "5b21699e-61b4-4317-c17d-e5e225c1cffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 20s 325ms/step - loss: 2.5070\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 15s 332ms/step - loss: 2.2259\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 15s 344ms/step - loss: 1.9836\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 16s 353ms/step - loss: 1.7745\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 1.7089\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 1.5962\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 1.5279\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 16s 351ms/step - loss: 1.4836\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 16s 356ms/step - loss: 1.4369\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 16s 357ms/step - loss: 1.4048\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 1.3884\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 16s 356ms/step - loss: 1.3701\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 16s 356ms/step - loss: 1.3502\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 1.3455\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.3388\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 16s 354ms/step - loss: 1.3274\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 1.3201\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 1.3067\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 1.3008\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 16s 357ms/step - loss: 1.3040\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 1.2862\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.2730\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 16s 355ms/step - loss: 1.2633\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.2388\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 16s 357ms/step - loss: 1.2273\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.2415\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 1.2163\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 16s 356ms/step - loss: 1.1968\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 16s 357ms/step - loss: 1.2334\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 1.1819\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.1682\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 1.1566\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 1.1494\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 16s 357ms/step - loss: 1.1318\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.1225\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 1.1114\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 16s 357ms/step - loss: 1.1020\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.1142\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 1.1009\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 1.0743\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.0650\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 16s 357ms/step - loss: 1.0544\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 1.0436\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.0533\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.0665\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 1.0571\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 1.0436\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 1.0203\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 16s 356ms/step - loss: 1.0163\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 1.0049\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 0.9714\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 0.9594\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 16s 356ms/step - loss: 0.9476\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 0.9388\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 0.9270\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 0.9170\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 0.9039\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 0.8929\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.8831\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.8963\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 0.8927\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 16s 357ms/step - loss: 0.8717\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.8459\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 0.8251\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 0.8110\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.7971\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 0.7815\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.7660\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 0.7484\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 0.7328\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 0.7608\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.7380\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 0.6942\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 0.6653\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 0.6790\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 0.6374\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.6117\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 0.5892\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.5658\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 16s 356ms/step - loss: 0.5447\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.5405\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.5582\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 0.5190\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.4903\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 0.4597\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 0.4377\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.4253\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.4109\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 0.3967\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 0.3829\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.3757\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 0.3661\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 0.3590\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 16s 354ms/step - loss: 0.3523\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 0.3469\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.3403\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.3326\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 0.3306\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 16s 355ms/step - loss: 0.3255\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 17s 388ms/step - loss: 0.3185\n"
     ]
    }
   ],
   "source": [
    "#обучение модели\n",
    "EPOCHS = 100\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5fa6cdf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03588adf",
    "outputId": "6db56579-e711-4b8e-e70e-e440bb530e1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 131) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "#предсказание модели\n",
    "example_batch_predictions = model(input_example_batch)\n",
    "print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26bb2600",
   "metadata": {
    "id": "3c14f0fa"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "177be428",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70f7c6f7",
    "outputId": "c041aaf8-306b-42e5-a4e8-44781b0f849a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " ' Позвольте мне, читатель мой,\\n                        Заняться старшею сестрой.\\n\\n                   '\n",
      "\n",
      "Next Char Predictions: \n",
      " ' ртнольте пне, митатель гой,\\n                        Ду явься старшею сестрой.\\n\\n                    '\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04def07b",
   "metadata": {
    "id": "Kdj2QYFhPjBS"
   },
   "source": [
    "### 2. Генерация текста <a id='section_2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aaaf9a7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qTf-4SL_Pny8",
    "outputId": "0b9660af-61d3-4122-fe53-d9ae6a055992"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./training_checkpoints/ckpt_100'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Находим имя файла последней сохраненной контрольной точки\n",
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35927406",
   "metadata": {
    "id": "T2B_i5L2Pr-T"
   },
   "outputs": [],
   "source": [
    "#строим модель\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "#загружаем веса из последней сохраненной контрольной точки в модель\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cb1ad1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2Gz-HD9Pvmu",
    "outputId": "e662e2bc-df8b-495c-b769-f832e9bb99d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 256)            33536     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (1, None, 1024)           5246976   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, None, 131)            134275    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,592,899\n",
      "Trainable params: 30,592,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#информация о модели\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b6575ab",
   "metadata": {
    "id": "twbxsO-9Px6k"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Этап оценки (генерация текста с использованием обученной модели)\n",
    "\n",
    "    # число букв для генераци\n",
    "    num_generate = 100\n",
    "\n",
    "    # Преобразование начальной строки в числа (векторизация)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    #Возвращаем тензор с осью длины 1, вставленной первой в индекс\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Пустая строка для хранения результатов\n",
    "    text_generated = []\n",
    "\n",
    "    # Низкая температура приводит к более предсказуемому тексту.\n",
    "    # Более высокая температура приводит к более неожиданному тексту.\n",
    "    temperature = 0.001\n",
    "\n",
    "    # здесь batch size == 1\n",
    "    # сбрасываем состояния всех слоев в модели\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        #получаем предсказания модели\n",
    "        predictions = model(input_eval)\n",
    "        #удаляем первую размерность в предсказании\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # использование категориального распределения для прогнозирования символа, возвращаемого моделью\n",
    "        predictions = predictions / temperature\n",
    "        #извлекаем выборку из категориального распределения\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Передаем предсказанный символ в качестве следующего ввода в модель\n",
    "        # вместе с предыдущим скрытым состоянием \n",
    "        # добавляем 1 первым индексом к размерности\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        #сохраняем предсказанную букву\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "79751d34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eb8MsKeDP5Q-",
    "outputId": "55106439-a62a-4d15-e7b0-ee2481768039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вот он идет был небес,\n",
      "                        И в молчаливом кабинете,\n",
      "                        И в молчаливом к\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, start_string=u\"Вот он идет \")\n",
    "print(text_)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW-09.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
