{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51ce9de",
   "metadata": {},
   "source": [
    "# Модель Transformer-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b8c57",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "1. Взять предобученную трансформерную архитектуру и решить задачу перевода\n",
    "2. (дополнительная не обязательная задача) взять датасет из datasets для задачи классификации на русском языке затем взять модель которая предобучена на такой задачи классификации и замерить качество до обучения и после обучения на этом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a4fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc90b59",
   "metadata": {},
   "source": [
    "#### Перевод с английского на немецкий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36491d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcWriteOptions size changed, may indicate binary incompatibility. Expected 72 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow._fs.FileInfo size changed, may indicate binary incompatibility. Expected 64 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow._fs.FileSelector size changed, may indicate binary incompatibility. Expected 48 from C header, got 72 from PyObject\n",
      "Found cached dataset opus_books (/home/zia/.cache/huggingface/datasets/opus_books/de-en-lang1=de,lang2=en/0.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d07299c3bc4b4cbf8b3fc074579107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузка датасета\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"opus_books\", lang1=\"de\", lang2=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0345908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 51467\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da503e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/zia/.cache/huggingface/datasets/opus_books/de-en-lang1=de,lang2=en/0.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf/cache-ddfbfb99a6bf2447.arrow and /home/zia/.cache/huggingface/datasets/opus_books/de-en-lang1=de,lang2=en/0.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf/cache-c2c940abbaa9f592.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 46320\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 5147\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разбивка данных на тренировочную и тестовую выборки\n",
    "\n",
    "split_datasets = dataset[\"train\"].train_test_split(train_size=0.9, seed=17)\n",
    "split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52b6936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de': '»Sie werden die ägyptischen Pyramiden hinaufklettern!« murmelte er. »Aber annoncieren Sie nur immer auf Ihre eigene Gefahr hin!',\n",
       " 'en': '\"You shall walk up the pyramids of Egypt!\" he growled. \"At your peril you advertise!'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример данных\n",
    "\n",
    "split_datasets[\"train\"][1][\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3693c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6218f1e5f418464c911e31a43007d9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41596d7b5d154f9cbb4ada0a4053e820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093e1c8f353e4b2f91539ce706179aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5269dcbccbc1491786bfb68f44a985ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zia/anaconda3/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Загрузка пайплайна\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "trans_lator= pipeline(\"translation_en_to_de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f79ac54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Wie sind Sie?'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка работы пайплайна\n",
    "\n",
    "trans_lator(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64092dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280101f05f5c405b913b48aca8ad0632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530824a319584ec4a739613496143396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7da425b32144197b973fe75cb49a84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c05384cbbf64d35b23bcff5623578fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8426fd1f1a754adbadb7f4b094d8b944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузка предобученного токенайзера\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-de\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "312cf53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zia/anaconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3606: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Разбивка данных по языкам и токенизация\n",
    "\n",
    "en_sentence = split_datasets[\"train\"][1][\"translation\"][\"en\"]\n",
    "de_sentence = split_datasets[\"train\"][1][\"translation\"][\"de\"]\n",
    "\n",
    "inputs = tokenizer(en_sentence)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    targets = tokenizer(de_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5103df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Препроцессинг\n",
    "\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"de\"] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0653fc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = split_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "689c9b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e5230b04654884a49bb5bcff4f988f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 17:44:48.554901: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-05-28 17:44:48.555209: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-28 17:44:48.555236: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ZIA): /proc/driver/nvidia/version does not exist\n",
      "2023-05-28 17:44:48.556083: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-28 17:44:49.001337: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 118990848 exceeds 10% of free system memory.\n",
      "2023-05-28 17:44:49.163388: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 118990848 exceeds 10% of free system memory.\n",
      "2023-05-28 17:44:49.182437: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 118990848 exceeds 10% of free system memory.\n",
      "2023-05-28 17:44:50.927162: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 118990848 exceeds 10% of free system memory.\n",
      "2023-05-28 17:44:51.058355: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 118990848 exceeds 10% of free system memory.\n",
      "All PyTorch model weights were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the weights of TFMarianMTModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка предобученной модели\n",
    "\n",
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12717b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перевод\n",
    "\n",
    "text = 'As God is my witness, I’ll never be hungry again!'\n",
    "\n",
    "inputs = tokenizer.encode(text, return_tensors=\"tf\")\n",
    "outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee354875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Da Gott mein Zeuge ist, werde ich nie wieder hungrig sein!</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a43f3",
   "metadata": {},
   "source": [
    "#### Классификация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abc643d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e9e756b13147aa97fed747b8ee7ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/495 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09604c386634ad9b77994d36331ae7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5820ca087de64d768528ec478c4c7557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce509b240fc4114a0b33b375fb4b04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/950 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc01a4b434cd4493a5d6c44b07cc11a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/712M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at blanchefort/rubert-base-cased-sentiment-rurewiews were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at blanchefort/rubert-base-cased-sentiment-rurewiews.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Импорт библиотек, загрузка токенизатора и модели \n",
    "\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment-rurewiews', return_tensors=\"tf\")\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment-rurewiews', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3460fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка пайплайна\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", tokenizer = tokenizer, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "836c4f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4cab4ff7be44cbbb26ab9122050a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0b2f8f6c824028acec0709aecd17e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/784 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset healthcare_facilities_reviews/simple to /home/zia/.cache/huggingface/datasets/blinoff___healthcare_facilities_reviews/simple/1.0.0/d61498aa2f506f5e71bb46794c1b010c56c842dd03b36556cb67744a57dc916e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1902e10c5a14708b6fb18618600c714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4465d24b4697446e81c1e4aac5acd1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/95.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80acbccf41fd465893078945055a4b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset healthcare_facilities_reviews downloaded and prepared to /home/zia/.cache/huggingface/datasets/blinoff___healthcare_facilities_reviews/simple/1.0.0/d61498aa2f506f5e71bb46794c1b010c56c842dd03b36556cb67744a57dc916e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d0bd3ecbd34b458344673920e1e201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузка датасета\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"blinoff/healthcare_facilities_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6167020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content', 'title', 'sentiment', 'category', 'review_id', 'source_url', 'Idx'],\n",
       "        num_rows: 70597\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['content', 'title', 'sentiment', 'category', 'review_id', 'source_url', 'Idx'],\n",
       "        num_rows: 70597\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2eed53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исключение лишниш столбцов\n",
    "\n",
    "dataset = dataset.remove_columns(['title', 'category', 'review_id', 'source_url', 'Idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5312edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/70597 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/70597 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Энкодинг таргета\n",
    "\n",
    "dataset = dataset.rename_column('sentiment', 'label')\n",
    "dataset = dataset.class_encode_column('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b74e4798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content', 'label'],\n",
       "        num_rows: 63537\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['content', 'label'],\n",
       "        num_rows: 7060\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разбивка данных на тренировочную и тестовую выборки\n",
    "\n",
    "split_datasets = dataset[\"train\"].train_test_split(train_size=0.9, seed=17)\n",
    "split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e272123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'При госпитализации в больницу могут предложить услуги посредника! Особенно наглый Корпорация семейной медицины! Сумма госпитализации завышена в разы ( говорят, что берут за курацию), договор дают не на госпитализацию, а общий! Потом еще требуют доплаты хотя в платном отделе больницы счет меньше! Ужас!', 'label': 0} {'content': 'Ужасное отношение, диагноз выдуман, снимок не смог нормально прочитать стоматолог. Не советую! Прием 15.08.15.', 'label': 0} {'content': 'В нашей семье случилась беда. Сын стал наркоманом. Мы узнали о клинике доктора Исаева случайно, т. к. не обладали никакой информацией по этому вопросу. Сына после клиники отправили в центр \"Не зависимость\", где с ним занималась Марьяна-мониторный психолог. Благодаря её профессионализму, самоотдаче, чётко проведённой методике, душевности. чуткости и заботе наш сын стал совершенно другим человеком. Нет слов, чтобы выразить от всего сердца благодарность Марьяне. Побольше бы таких высококлассных специалистов!Михаил, папа Л.', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# Пример данных\n",
    "\n",
    "print(split_datasets[\"train\"][0],\n",
    "      split_datasets[\"train\"][1],\n",
    "      split_datasets[\"train\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eda79a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.8474008440971375}] [{'label': 'NEGATIVE', 'score': 0.9199402928352356}] [{'label': 'NEGATIVE', 'score': 0.7423567175865173}]\n"
     ]
    }
   ],
   "source": [
    "# Проверка работы предобученной модели\n",
    "\n",
    "print(classifier(split_datasets[\"train\"]['content'][0]),\n",
    "      classifier(split_datasets[\"train\"]['content'][1]),\n",
    "      classifier(split_datasets[\"train\"]['content'][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd809932",
   "metadata": {},
   "source": [
    "В одном случае из трех предобученная модель ошиблась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = split_datasets[\"test\"][\"content\"]\n",
    "raw_predictions = classifier(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d42993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87b6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
